# Coleta de dados - Web Scraping

Uma das etapas de um projeto data science é a coleta de dados, Web Scraping é um método de coleta onde podemos usar a ferramenta Selenium do Python para realizar automação web.<br>
O intuito deste material é apresentar a biblioteca Selenium do python, com ela vamos aprender métodos e módulos para extração de dados via web.<br>

# Instalando o Selenium

No Jupyter Notebook ou no prompt de comando do anaconda digite o comando abaixo para instalar o Selenium:

        - pip install --upgrade selenium
        
Para fazer automação web o navegador mais indicado é o Google Chrome, se não tiver use o link abaixo:

- <a href="https://www.google.com/chrome/"> Clique para baixar o Google Chrome</a>

Após instalado abra o navegador e digite para saber a versão do seu Chrome:

        - chrome://settings/help

# Instalando o web driver

O WebDriver manipula um navegador nativamente, como um usuário faria, seja localmente ou em uma máquina remota usando o servidor Selenium, marca um salto em termos de automação do navegador.<br>
- Selenium WebDriver é uma recomendação W3C
- WebDriver é projetado como uma interface de programação simples e mais concisa.
- WebDriver é uma API compacta orientada a objetos. 
- Ele manipula o navegador de forma eficaz.

- <a href="https://www.selenium.dev/pt-br/documentation/webdriver/"> Clique para baixar o Web Driver</a>
